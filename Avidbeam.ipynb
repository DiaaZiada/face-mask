{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Avidbeam.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh3zGWVnvnXe"
      },
      "source": [
        "import os\n",
        "from time import time\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import SubsetRandomSampler, DataLoader, Dataset\n",
        "from torchvision import  datasets, transforms, models, get_image_backend\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from matplotlib import pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9s-fbmjczSL"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "**Link to download the dataset** [Here](https://www.kaggle.com/omkargurav/face-mask-dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q3aQ5nwuEHA"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq4w6HB5uKhL"
      },
      "source": [
        "!unzip /content/drive/MyDrive/archive.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpN0w979ucNs"
      },
      "source": [
        "!ls /content/data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T6yi8qxykS5"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf9ZgwT20d3g"
      },
      "source": [
        "## Transformation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sF3fWZC0bhZ"
      },
      "source": [
        "train_transforms = transforms.Compose([\n",
        "                                        transforms.ToPILImage(),\n",
        "                                        transforms.Scale((64,64)),\n",
        "                                        transforms.ToTensor()\n",
        "                                      ])\n",
        "test_transforms = transforms.Compose([\n",
        "                                        transforms.ToPILImage(),\n",
        "                                        transforms.Scale((64,64)),\n",
        "                                     ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwTsNykvymhW"
      },
      "source": [
        "def one_hot_encoder(data, words=True):  \n",
        "\n",
        "    values = np.array(data)  \n",
        "    d = {}\n",
        "    if words:\n",
        "        label_encoder = LabelEncoder()\n",
        "        integer_encoded = label_encoder.fit_transform(values) \n",
        "    else:\n",
        "        integer_encoded = values\n",
        "    \n",
        "    onehot_encoder = OneHotEncoder(sparse=False)\n",
        "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)    \n",
        "    return integer_encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxfEij6O3OuO"
      },
      "source": [
        "def imshow(img):\n",
        "    \n",
        "    plt.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image\n",
        "def displaying_data(dataiter, dic):\n",
        "    # obtain one batch of training images\n",
        "    images, labels = dataiter.next()\n",
        "    images = images.numpy() # convert images to numpy for display\n",
        "\n",
        "    # plot the images in the batch, along with the corresponding labels\n",
        "    fig = plt.figure(figsize=(25, 4))\n",
        "    # display 20 images\n",
        "    for idx in np.arange(20):\n",
        "        ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "        try:\n",
        "            imshow(images[idx][0])\n",
        "        except:\n",
        "            imshow(images[idx])\n",
        "\n",
        "        ax.set_title(dic[int(labels[idx])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yh7Iud6Tsgw5"
      },
      "source": [
        "## DataParser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6lgXxjCsgJt"
      },
      "source": [
        "class Data:\n",
        "    def __init__(self, path):\n",
        "        with_mask_dir = \"with_mask\"\n",
        "        without_mask_dir = \"without_mask\"\n",
        "        self.images_path, self.labels = self.load_data(path, with_mask_dir, without_mask_dir)\n",
        "\n",
        "    def load_data(self, path, with_mask_dir, without_mask_dir):\n",
        "        with_mask_path = os.path.join(path, with_mask_dir)\n",
        "        without_mask_path = os.path.join(path, without_mask_dir)\n",
        "\n",
        "        with_mask_images = os.listdir(with_mask_path)\n",
        "        without_mask_images = os.listdir(without_mask_path)\n",
        "\n",
        "        images_path = [os.path.join(with_mask_path, image) for image in with_mask_images]\n",
        "        images_path += [os.path.join(without_mask_path, image) for image in without_mask_images]\n",
        "        \n",
        "        labels = [\"withMask\" for _ in range(len(with_mask_images))]\n",
        "        labels += [\"withOutMask\" for _ in range(len(without_mask_images))]\n",
        "        \n",
        "        return images_path, one_hot_encoder(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8BSg1UJy--G"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ezuxCFszeVK"
      },
      "source": [
        "def default_loader(image_path):\n",
        "    return cv2.imread(image_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlT8c8bWx46-"
      },
      "source": [
        "class ImageDataSets(Dataset):\n",
        "    def __init__(self,data_path, transform=None, image_loader=default_loader):\n",
        "        self.data = Data(data_path)\n",
        "        self.loader = image_loader\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data.images_path)\n",
        "\n",
        "    def __getitem__(self,indx):\n",
        "        image = self.loader(self.data.images_path[indx])\n",
        "        label = self.data.labels[indx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image,label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mqNllo8yOwD"
      },
      "source": [
        "\n",
        "valid_size = 0.2\n",
        "test_size = 0\n",
        "\n",
        "train_dataset = ImageDataSets(\"/content/data\", train_transforms)\n",
        "\n",
        "test_dataset = ImageDataSets(\"/content/data\", test_transforms)\n",
        "\n",
        "train_size = len(train_dataset)\n",
        "\n",
        "indices = list(range(train_size))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "valid_split_size = int(valid_size * train_size)\n",
        "test_split_size = int(test_size * train_size)\n",
        "\n",
        "train_indices, test_indices, valid_indices = indices[test_split_size + valid_split_size:], indices[:test_split_size], indices[test_split_size:test_split_size + valid_split_size]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(valid_indices)\n",
        "test_sampler = SubsetRandomSampler(test_indices)\n",
        "\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0mCycsX1WD5"
      },
      "source": [
        "train_loader = DataLoader(train_dataset,batch_size=batch_size,sampler=train_sampler)\n",
        "valid_loader = DataLoader(train_dataset,batch_size=batch_size,sampler=valid_sampler)\n",
        "test_loader = DataLoader(test_dataset,batch_size=batch_size,sampler=valid_sampler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riH0Cm6X-Y55"
      },
      "source": [
        "dataiter = iter(train_loader)\n",
        "displaying_data(dataiter,{0:'Mask', 1:\"No Mask\"})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XunRkzuF-7ft"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r7UujEAu1wy"
      },
      "source": [
        "class SeparableConv2d(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels,kernel_size=1,stride=1,padding=0,dilation=1,bias=False):\n",
        "        super(SeparableConv2d,self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels,in_channels,kernel_size,stride,padding,dilation,groups=in_channels,bias=bias)\n",
        "        self.pointwise = nn.Conv2d(in_channels,out_channels,1,1,0,1,1,bias=bias)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.pointwise(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LfKILVxvrOw"
      },
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self,in_filters,out_filters,reps,strides=2,start_with_relu=True,grow_first=True):\n",
        "        super(Block, self).__init__()\n",
        "\n",
        "        if out_filters != in_filters or strides!=1:\n",
        "            self.skip = nn.Conv2d(in_filters,out_filters,1,stride=strides, bias=False)\n",
        "            self.skipbn = nn.BatchNorm2d(out_filters)\n",
        "        else:\n",
        "            self.skip=None\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        rep=[]\n",
        "\n",
        "        filters=in_filters\n",
        "        if grow_first:\n",
        "            rep.append(self.relu)\n",
        "            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n",
        "            rep.append(nn.BatchNorm2d(out_filters))\n",
        "            filters = out_filters\n",
        "\n",
        "        for i in range(reps-1):\n",
        "            rep.append(self.relu)\n",
        "            rep.append(SeparableConv2d(filters,filters,3,stride=1,padding=1,bias=False))\n",
        "            rep.append(nn.BatchNorm2d(filters))\n",
        "        \n",
        "        if not grow_first:\n",
        "            rep.append(self.relu)\n",
        "            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n",
        "            rep.append(nn.BatchNorm2d(out_filters))\n",
        "\n",
        "        if not start_with_relu:\n",
        "            rep = rep[1:]\n",
        "        else:\n",
        "            rep[0] = nn.ReLU(inplace=False)\n",
        "            \n",
        "        if strides != 1:\n",
        "            rep.append(nn.MaxPool2d(3,strides,1))\n",
        "        self.rep = nn.Sequential(*rep)\n",
        "        \n",
        "\n",
        "    def forward(self,inp):\n",
        "        x = self.rep(inp)\n",
        "\n",
        "        if self.skip is not None:\n",
        "            skip = self.skip(inp)\n",
        "            skip = self.skipbn(skip)\n",
        "        else:\n",
        "            skip = inp\n",
        "                            \n",
        "        x+=skip\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hil3YXCvxuP"
      },
      "source": [
        "class FeatureExtractor(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        \n",
        "        self.con2d_1 = nn.Conv2d(in_channels=3,out_channels=8,\n",
        "                                  kernel_size=(3, 3), stride=(1, 1), padding=0, bias=False)\n",
        "        self.bn_1 = nn.BatchNorm2d(8)\n",
        "        \n",
        "        self.con2d_2 = nn.Conv2d(in_channels=8,out_channels=8,\n",
        "                                  kernel_size=(3, 3), stride=(1, 1), padding=0, bias=False)\n",
        "        self.bn_2 = nn.BatchNorm2d(8)\n",
        "        self.block_1 = Block(in_filters=8, out_filters=16,reps=2)\n",
        "        self.block_2 = Block(in_filters=16, out_filters=32,reps=2)\n",
        "        self.block_3 = Block(in_filters=32, out_filters=64,reps=2)\n",
        "        self.block_4 = Block(in_filters=64, out_filters=128,reps=2)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.con2d_1(x)\n",
        "        x = self.bn_1(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.con2d_2(x)\n",
        "        x = self.bn_2(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.block_3(x)\n",
        "        x = self.block_4(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sihmhjYGv27Q"
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_classes):\n",
        "        super(Classifier, self).__init__()\n",
        "        \n",
        "        self.conv2d_f = nn.Conv2d(in_channels=128, out_channels=num_classes,\n",
        "                                  kernel_size=(3, 3), stride=(1, 1), padding=1)\n",
        "        self.glob_avg_bool = nn.AvgPool2d(kernel_size=(3, 3))\n",
        "        \n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv2d_f(x)\n",
        "        x = self.glob_avg_bool(x)\n",
        "#         x = self.softmax(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN_QJWUjv6CT"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    \n",
        "    def __init__(self,num_classes):\n",
        "        super(Model, self).__init__()\n",
        "        \n",
        "        self.feature_extractor = FeatureExtractor()\n",
        "        self.classifier = Classifier(num_classes)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = self.classifier(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M2C4_1BcFSz"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.up2 = nn.ConvTranspose2d(64, 32, 2, stride=2)\n",
        "        self.up3 = nn.ConvTranspose2d(32,16, 2, stride=2)\n",
        "        self.up4 = nn.ConvTranspose2d(16, 3, 2, stride=2)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.up1(x)  \n",
        "        x = self.up2(x)      \n",
        "        x = self.up3(x)      \n",
        "        x = self.up4(x)      \n",
        "        # x = self.up5(x)      \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XTE76x6v9Q2"
      },
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "        self.encoder =  FeatureExtractor()\n",
        "        self.decoder = Decoder()\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.encoder(x)  \n",
        "        x = self.decoder(x)           \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_VwMsRlALHK"
      },
      "source": [
        "# Train AutoEncoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoIUHiKUwAsl"
      },
      "source": [
        "def train(train_loader, model, optimizer, criterion):\n",
        "    model.train()\n",
        "    t = time()\n",
        "    train_loss = 0\n",
        "    for data in tqdm.notebook.tqdm(train_loader):\n",
        "        images = data[0]\n",
        "        labels = data[1]\n",
        "        images = images.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = criterion(output, images)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    return train_loss / len(train_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNexF-wGS_Mb"
      },
      "source": [
        "def validation(valid_loader, model, criterion):\n",
        "    model.eval()\n",
        "    validation_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm.notebook.tqdm(valid_loader):\n",
        "            images = data[0]\n",
        "            labels = data[1]\n",
        "            images = images.cuda()\n",
        "            output = model(images)\n",
        "            loss = criterion(output, images)\n",
        "            validation_loss += loss.item()\n",
        "    return validation_loss / len(valid_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36qRKuJZBslH"
      },
      "source": [
        "criterion = nn.MSELoss()\n",
        "auto_encoder = AutoEncoder()\n",
        "\n",
        "auto_encoder = auto_encoder.cuda()\n",
        "optimizer = optim.Adam(auto_encoder.parameters(), lr=0.001)\n",
        "min_loss = np.inf\n",
        "stop_counter = 0\n",
        "train_losses = []\n",
        "validatoin_losses = []\n",
        "for i in tqdm.notebook.tqdm(range(1000)):\n",
        "    t_loss = train(train_loader, auto_encoder, optimizer, criterion)\n",
        "    v_loss = validation(valid_loader, auto_encoder, criterion)\n",
        "    \n",
        "    train_losses.append(t_loss)\n",
        "    validatoin_losses.append(v_loss)\n",
        "\n",
        "    min_loss = min(min_loss, v_loss)\n",
        "    print(\"loss: \",v_loss, end=\" \")\n",
        "    if min_loss != v_loss:\n",
        "        print(\"BAD \", stop_counter)\n",
        "        stop_counter += 1\n",
        "\n",
        "    else:\n",
        "        print(\"Better\")\n",
        "        stop_counter = 0\n",
        "        torch.save(auto_encoder.state_dict(), \"/content/model.pth\")\n",
        "\n",
        "    if stop_counter == 10:\n",
        "        break\n",
        "    break\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2QSphYMwCSY"
      },
      "source": [
        "def display_graph(train_losses, valid_losses):\n",
        "    plt.plot(train_losses, label='Training loss')\n",
        "    plt.plot(valid_losses, label='Validation loss')\n",
        "    plt.legend(frameon=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lNj2pcRcCLN"
      },
      "source": [
        "display_graph(train_losses, validatoin_losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMJXjKse4_7O"
      },
      "source": [
        "# Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veKu6C765rEP"
      },
      "source": [
        "auto_encoder = AutoEncoder()\n",
        "auto_encoder.cuda()\n",
        "auto_encoder.load_state_dict(torch.load(\"/content/model.pth\"))\n",
        "torch.save(auto_encoder.encoder.state_dict(), \"/content/encoder.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC5vdd1DwGVl"
      },
      "source": [
        "model = Model(2)\n",
        "model.cuda()\n",
        "model.feature_extractor.load_state_dict(torch.load( \"/content/encoder.pth\"))\n",
        "for param in model.feature_extractor.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuEZhsA44_J5"
      },
      "source": [
        "def train_classifier(train_loader, model, optimizer, criterion):\n",
        "    model.train()\n",
        "    t = time()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    for data in tqdm.notebook.tqdm(train_loader):\n",
        "        images = data[0]\n",
        "        labels = data[1]\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        output = output.reshape(-1, 2)\n",
        "        labels = labels.reshape(-1)\n",
        "        loss = criterion(output, labels)\n",
        "\n",
        "        correct += (torch.argmax(output, axis=1) == labels).float().sum()\n",
        "        # print(correct/32)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    print(int((correct/(len(train_loader)*32)*100)))\n",
        "    return train_loss / len(train_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O9C-BoPb-vK"
      },
      "source": [
        "def validation_classifer(valid_loader, model, criterion):\n",
        "    model.eval()\n",
        "    validation_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm.notebook.tqdm(valid_loader):\n",
        "            images = data[0]\n",
        "            labels = data[1]\n",
        "            labels = labels.cuda()\n",
        "            images = images.cuda()\n",
        "            output = model(images)\n",
        "            output = output.reshape(-1, 2)\n",
        "            labels = labels.reshape(-1)\n",
        "            correct += (torch.argmax(output, axis=1) == labels).float().sum()\n",
        "            # print(correct/32)\n",
        "            loss = criterion(output, labels)\n",
        "            validation_loss += loss.item()\n",
        "    print(int((correct/(len(valid_loader)*32)*100)))\n",
        "\n",
        "    return validation_loss / len(valid_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjt8GqKdc4Mn"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "min_loss = np.inf\n",
        "stop_counter = 0\n",
        "train_losses = []\n",
        "validatoin_losses = []\n",
        "for i in tqdm.notebook.tqdm(range(1000)):\n",
        "    t_loss = train_classifier(train_loader, model, optimizer, criterion)\n",
        "    v_loss = validation_classifer(valid_loader, model, criterion)\n",
        "    \n",
        "    train_losses.append(t_loss)\n",
        "    validatoin_losses.append(v_loss)\n",
        "\n",
        "    min_loss = min(min_loss, v_loss)\n",
        "    print(\"loss: \",v_loss, end=\" \")\n",
        "    if min_loss != v_loss:\n",
        "        print(\"BAD \", stop_counter, i)\n",
        "        stop_counter += 1\n",
        "\n",
        "    else:\n",
        "        print(\"Better\")\n",
        "        stop_counter = 0\n",
        "        torch.save(model.state_dict(), \"/content/classifer_model.pth\")\n",
        "\n",
        "    if stop_counter == 10:\n",
        "        break\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AVF60oDsfFB"
      },
      "source": [
        "display_graph(train_losses, validatoin_losses)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}